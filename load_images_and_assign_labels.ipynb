{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "## Generate batches of tensor image data with real-time data augmentation.\n",
    "## https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "## The paths sub-module of imutils includes a function to recursively find images \n",
    "## based on a root directory.\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "## Parser for command-line options, arguments and sub-commands\n",
    "import argparse\n",
    "## OpenCV\n",
    "import cv2\n",
    "\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define load_data function \n",
    "To load all images under a given directory and assign them with the same label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to load all images in a specific directory\n",
    "def load_data(path, label):\n",
    "    print(\"[INFO] loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    imagePaths = sorted(list(paths.list_images(path)))\n",
    "    # loop over the input images\n",
    "    for imagePath in imagePaths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list   \n",
    "        labels.append(label)\n",
    "    \n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    data = np.array(data, dtype=\"float\")\n",
    "    labels = np.array(labels)                        \n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Specify image locations and assign labels\n",
    "Here we use imagenette as an example.\n",
    "Refer to https://github.com/fastai/imagenette for download links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tench images\n",
      "[INFO] loading images...\n",
      "Load English springer images\n",
      "[INFO] loading images...\n",
      "Load cassette player images\n",
      "[INFO] loading images...\n",
      "Load chain saw images\n",
      "[INFO] loading images...\n",
      "Load church images\n",
      "[INFO] loading images...\n",
      "Load French horn images\n",
      "[INFO] loading images...\n",
      "Load garbage truck images\n",
      "[INFO] loading images...\n",
      "Load gas pump images\n",
      "[INFO] loading images...\n",
      "Load golf ball images\n",
      "[INFO] loading images...\n",
      "Load parachute images\n",
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "classes= {'tench': 0, 'English springer': 1, 'cassette player': 2, 'chain saw': 3, 'church': 4,\n",
    "         'French horn': 5, 'garbage truck': 6, 'gas pump': 7, 'golf ball': 8, 'parachute': 9}\n",
    "print(\"Load tench images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n01440764\"\n",
    "data1, labels1 = load_data(path, 0)\n",
    "\n",
    "print(\"Load English springer images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n02102040\"\n",
    "data2, labels2 = load_data(path, 1)\n",
    "\n",
    "print(\"Load cassette player images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n02979186\"\n",
    "data3, labels3 = load_data(path, 2)\n",
    "\n",
    "print(\"Load chain saw images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n03000684\"\n",
    "data4, labels4 = load_data(path, 3)\n",
    "\n",
    "print(\"Load church images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n03028079\"\n",
    "data5, labels5 = load_data(path, 4)\n",
    "\n",
    "print(\"Load French horn images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n03394916\"\n",
    "data6, labels6 = load_data(path, 5)\n",
    "\n",
    "print(\"Load garbage truck images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n03417042\"\n",
    "data7, labels7 = load_data(path, 6)\n",
    "\n",
    "print(\"Load gas pump images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n03425413\"\n",
    "data8, labels8 = load_data(path, 7)\n",
    "\n",
    "print(\"Load golf ball images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n03445777\"\n",
    "data9, labels9 = load_data(path, 8)\n",
    "\n",
    "print(\"Load parachute images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\train\\\\n03888257\"\n",
    "data10, labels10 = load_data(path, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidate all training batches into a single training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9469, 224, 224, 3)\n",
      "(9469,)\n"
     ]
    }
   ],
   "source": [
    "x_train_full = np.concatenate((data1, data2, data3, data4, data5, data6, data7, data8, data9, data10), axis = 0)\n",
    "y_train_full = np.concatenate((labels1, labels2, labels3, labels4, labels5, labels6, labels7, labels8, labels9, labels10), axis = 0)\n",
    "print(x_train_full.shape)\n",
    "print(y_train_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the training examples randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 7 ... 0 6 4]\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "x_train, y_train = unison_shuffled_copies(x_train_full, y_train_full)\n",
    "print(y_train)\n",
    "# Split the training set into a training set and an validation set with a split ratio of 9 : 1.\n",
    "(x_train, x_valid, y_train, y_valid) = train_test_split(x_train, y_train, test_size=0.1, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load tench images\n",
      "[INFO] loading images...\n",
      "Load English springer images\n",
      "[INFO] loading images...\n",
      "Load cassette player images\n",
      "[INFO] loading images...\n",
      "Load chain saw images\n",
      "[INFO] loading images...\n",
      "Load church images\n",
      "[INFO] loading images...\n",
      "Load French horn images\n",
      "[INFO] loading images...\n",
      "Load garbage truck images\n",
      "[INFO] loading images...\n",
      "Load gas pump images\n",
      "[INFO] loading images...\n",
      "Load golf ball images\n",
      "[INFO] loading images...\n",
      "Load parachute images\n",
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"Load tench images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n01440764\"\n",
    "data1, labels1 = load_data(path, 0)\n",
    "\n",
    "print(\"Load English springer images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n02102040\"\n",
    "data2, labels2 = load_data(path, 1)\n",
    "\n",
    "print(\"Load cassette player images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n02979186\"\n",
    "data3, labels3 = load_data(path, 2)\n",
    "\n",
    "print(\"Load chain saw images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n03000684\"\n",
    "data4, labels4 = load_data(path, 3)\n",
    "\n",
    "print(\"Load church images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n03028079\"\n",
    "data5, labels5 = load_data(path, 4)\n",
    "\n",
    "print(\"Load French horn images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n03394916\"\n",
    "data6, labels6 = load_data(path, 5)\n",
    "\n",
    "print(\"Load garbage truck images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n03417042\"\n",
    "data7, labels7 = load_data(path, 6)\n",
    "\n",
    "print(\"Load gas pump images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n03425413\"\n",
    "data8, labels8 = load_data(path, 7)\n",
    "\n",
    "print(\"Load golf ball images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n03445777\"\n",
    "data9, labels9 = load_data(path, 8)\n",
    "\n",
    "print(\"Load parachute images\")\n",
    "path = \"C:\\\\Users\\\\hli36\\\\OneDrive\\\\Learning\\\\Resources\\\\imagenette2\\\\val\\\\n03888257\"\n",
    "data10, labels10 = load_data(path, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidate all test batches into a single test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples is: 8522\n",
      "The number of validation examples is: 947\n",
      "The number of test examples is: 3925\n"
     ]
    }
   ],
   "source": [
    "x_test = np.concatenate((data1, data2, data3, data4, data5, data6, data7, data8, data9, data10), axis = 0)\n",
    "y_test = np.concatenate((labels1, labels2, labels3, labels4, labels5, labels6, labels7, labels8, labels9, labels10), axis = 0)\n",
    "x_test, y_test = unison_shuffled_copies(x_test, y_test)\n",
    "print('The number of training examples is:', x_train.shape[0])\n",
    "print('The number of validation examples is:', x_valid.shape[0])\n",
    "print('The number of test examples is:', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenette2 = {\"x_train\": x_train,\n",
    "#              \"y_train\": y_train,\n",
    "#              \"x_valid\": x_valid,\n",
    "#              \"y_valid\": y_valid,\n",
    "#              \"x_test\": x_test,\n",
    "#              \"y_test\": y_test,\n",
    "#              \"classes\": classes}\n",
    "##np.save('imagenette2', imagenette2)\n",
    "np.savez_compressed('x_train', x_train)\n",
    "np.savez_compressed('y_train', y_train)\n",
    "np.savez_compressed('x_valid', x_valid)\n",
    "np.savez_compressed('y_valid', y_valid)\n",
    "np.savez_compressed('x_test', x_test)\n",
    "np.savez_compressed('y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
